{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64ec2f0f",
   "metadata": {},
   "source": [
    "# Lesson 3: Building an Agent Reasoning Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d7f1cf",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b07baa43-7a51-4c39-91cc-aa0d9619b69f",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from helper import get_openai_api_key\n",
    "OPENAI_API_KEY = get_openai_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcfa86a3-c7f2-41fa-b8b6-5617659ec36a",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3af4bb",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8bfb34",
   "metadata": {
    "tags": []
   },
   "source": [
    "To download this paper, below is the needed code:\n",
    "\n",
    "#!wget \"https://arxiv.org/pdf/2405.13063\" -O AURORA A FOUNDATION MODEL OF THE ATMOSPHERE.pdf\n",
    "\n",
    "**Note**: The pdf file is included with this lesson. To access it, go to the `File` menu and select`Open...`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb741560",
   "metadata": {},
   "source": [
    "## Setup the Query Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77464fb2-5ace-4839-9032-a020df8d4259",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import get_doc_tools\n",
    "\n",
    "vector_tool, summary_tool = get_doc_tools(\"AURORA A FOUNDATION MODEL OF THE ATMOSPHERE.pdf\", \"AURORA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40aae3fc",
   "metadata": {},
   "source": [
    "## Setup Function Calling Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff4f5199-d02c-47b0-a9ab-cf72c8a506a3",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9365d78d-8e9f-4f22-8d57-35a4c6aa6baf",
   "metadata": {
    "height": 166,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.agent import AgentRunner\n",
    "\n",
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    [vector_tool, summary_tool], \n",
    "    llm=llm, \n",
    "    verbose=True\n",
    ")\n",
    "agent = AgentRunner(agent_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a9535d7-0baf-4905-ad16-5fb903d33b85",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What experimental results validate Aurora's performance in predicting air pollution?, How does Aurora adapt to the non-stationary and scarce data from CAMS analysis?\n",
      "=== Calling Function ===\n",
      "Calling function: vector_tool_AURORA with args: {\"query\": \"experimental results validate Aurora's performance in predicting air pollution\"}\n",
      "=== Function Output ===\n",
      "Experimental results validate Aurora's performance in predicting air pollution.\n",
      "=== Calling Function ===\n",
      "Calling function: vector_tool_AURORA with args: {\"query\": \"How does Aurora adapt to the non-stationary and scarce data from CAMS analysis?\"}\n",
      "=== Function Output ===\n",
      "Aurora adapts to the non-stationary and scarce data from CAMS analysis by fine-tuning on CAMS analysis data from a limited temporal extent and incorporating lower resolution CAMS reanalysis data in the fine-tuning process.\n",
      "=== LLM Response ===\n",
      "The experimental results validate Aurora's performance in predicting air pollution. Aurora adapts to the non-stationary and scarce data from CAMS analysis by fine-tuning on CAMS analysis data from a limited temporal extent and incorporating lower resolution CAMS reanalysis data in the fine-tuning process.\n"
     ]
    }
   ],
   "source": [
    "response = agent.query(\n",
    "    \"What experimental results validate Aurora's performance in predicting air pollution?, \"\n",
    "    \"How does Aurora adapt to the non-stationary and scarce data from CAMS analysis?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcf74ec4-559f-4284-9ed0-817d26951c54",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_label: 3\n",
      "file_name: AURORA A FOUNDATION MODEL OF THE ATMOSPHERE.pdf\n",
      "file_path: AURORA A FOUNDATION MODEL OF THE ATMOSPHERE.pdf\n",
      "file_type: application/pdf\n",
      "file_size: 9864973\n",
      "creation_date: 2024-06-08\n",
      "last_modified_date: 2024-06-08\n",
      "\n",
      "Aurora: A Foundation Model of the Atmosphere\n",
      "We pretrain Aurora on a vast body of weather and climate data. By including as much and as diverse data as possible,\n",
      "Aurora attempts to learn a general-purpose representation of atmospheric dynamics. The pretraining data is a mixture of\n",
      "six weather and climate datasets: ERA5, CMCC, IFS-HR, HRES Forecasts, GFS Analysis and GFS Forecasts. These\n",
      "datasets are a mixture of forecasts, analysis data, reanalysis data, and climate simulations. The pretraining datasets\n",
      "comprise a standard collection of meteorological variables (see Supplementary C for more details on the datasets).\n",
      "During pretraining, we minimise the next–time step mean absolute error (MAE) with a 6-hour lead time for 150 k\n",
      "steps on 32 A100 GPUs, which corresponds to approximately two and a half weeks of training. Once pretraining is\n",
      "completed, Aurora is ready to be fine-tuned for new atmospheric prediction tasks. Fine-tuning takes place in multiple\n",
      "stages, ending with a roll-out fine-tuning stage (Supplementary D).\n",
      "For lead times up to 15 days, the Integrated Forecasting System (IFS; European Centre for Medium-Range Weather\n",
      "Forecasts, 2023a) is the gold-standard and state-of-the-art numerical forecasting system. This system, however, operates\n",
      "at considerable computational cost: producing a 10-day forecast takes approximately 65 minutes on 352 high-end CPU\n",
      "nodes with 36 cores each (see section 2.1.5 in Buizza et al., 2018), corresponding to approximately 5720 node-seconds\n",
      "per hour lead time. In contrast, Aurora can make predictions at approximately 1.1 sper hour lead time on a single A100\n",
      "GPU, thus yielding roughly a ×5,000speedup over IFS.\n",
      "3 Fast prediction of atmospheric chemistry and air pollution\n",
      "We selected forecasting atmospheric chemistry and air pollution as our first application of Aurora due to its societal\n",
      "importance, the significant challenge it poses to data driven approaches, and the potential these methods hold for\n",
      "acceleration and improving accuracy.\n",
      "Air quality is a key factor in non-communicable disease and therefore the health of humans, and is determined by\n",
      "concentrations of various gasses and aerosols in the atmosphere (World Health Organization, 2021). Accurately\n",
      "predicting global atmospheric composition (the distribution of trace gases and aerosols in the air) can aid mitigation of\n",
      "air pollution events.\n",
      "Forecasting atmospheric composition is much more complex and costly than weather forecasting. Not only does\n",
      "atmospheric composition depend on transport via weather systems, atmospheric chemistry models also simulate\n",
      "nonlinear reactions between different chemical species through hundreds of stiff equations (Brasseur and Jacob, 2017).\n",
      "In addition, atmospheric composition strongly depends on anthropogenic emissions of trace gases and aerosols, which\n",
      "drive the heterogeneous levels of pollution seen across the globe. Predicting global atmospheric composition therefore\n",
      "requires a model to understand complex atmospheric chemistry and account for human behaviour.\n",
      "The Copernicus Atmosphere Monitoring Service (CAMS) is an operational system that produces forecasts, analysis\n",
      "products, and reanalysis products for global atmospheric composition (European Centre for Medium-Range Weather\n",
      "Forecasts, 2023b) at 0.4◦resolution. CAMS is an extension of IFS with additional modules for aerosols, reactive gases,\n",
      "and greenhouse gases. For the reasons mentioned above, these extension modules make the already computationally\n",
      "expensive IFS significantly more costly (by a factor of 10 ×, based on private communication with ECMWF). Although\n",
      "machine learning methods could amortise these computational costs and even improve accuracy, thus far no AI\n",
      "method has attempted to produce operational predictions for global atmospheric composition. In this experiment,\n",
      "we demonstrate that Aurora can be successfully fine-tuned to CAMS analysis data to produce operational forecasts\n",
      "that match or outperform CAMS forecasts in terms of RMSE on 74% of all targets, at orders of magnitude lower\n",
      "computational cost.\n",
      "Fine-tuning Aurora (or training any AI model) on CAMS analysis data is extremely challenging for three reasons. First,\n",
      "unlike NWP systems ( e.g., IFS) which are relatively stable across update cycles, CAMS undergoes frequent updates that\n",
      "significantly affect the data distribution. In addition, CAMS analysis data only goes back to 2015, and quality of the\n",
      "data generally decreases the further you go back. This means that CAMS analysis data is very scarce and non-stationary.\n",
      "Second, unlike meteorological variables, air pollution variables are concentration values with a large dynamic range.\n",
      "These variables are highly heterogeneous (Figure 2a), and often extremely sparse and skewed.\n"
     ]
    }
   ],
   "source": [
    "print(response.source_nodes[0].get_content(metadata_mode=\"all\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b28c184-0b65-4e38-808e-d91a285aaefe",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Tell me about the evaluation datasets used.\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_AURORA with args: {\"input\": \"evaluation datasets used in Aurora\"}\n",
      "=== Function Output ===\n",
      "The evaluation datasets used in Aurora consist of a wide range of meteorological datasets such as ERA5, CMCC, IFS-HR, HRES Forecasts, GFS Analysis, GFS Forecasts, CAMS analysis data, CAMS reanalysis data, CAMS analysis data with specific heuristic factors, 3D Perceiver encoder, Multi-scale 3D Swin Transformer U-Net backbone, 3D Perceiver decoder, Position, scale, level, and time encodings, Data normalization, Extensions for 0.1° weather forecasting, Extensions for air pollution forecasting, HRRR, CONUS404, and various other datasets like HRES-0.25, IFS-ENS-0.25, HRES-T0, HRES Analysis, IFS ENS, IFS ENS mean, GFS Forecast, GFS-T0 Analysis, GEFS Reforecast, CMCC-CM2-VHR4, ECMWF-IFS-HR, MERRA-2, CAMS, and CAMSRA. These datasets cover a diverse collection of weather variables, pressure levels, resolutions, and specific data types to train and fine-tune the Aurora model for improved forecasting capabilities.\n",
      "=== LLM Response ===\n",
      "The evaluation datasets used in Aurora include a wide range of meteorological datasets such as ERA5, CMCC, IFS-HR, HRES Forecasts, GFS Analysis, GFS Forecasts, CAMS analysis data, CAMS reanalysis data, and various other datasets covering weather variables, pressure levels, resolutions, and specific data types to train and fine-tune the Aurora model for improved forecasting capabilities.\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\n",
    "    \"Tell me about the evaluation datasets used.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9586cef-21b5-4732-b95d-619462b4aaf6",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Tell me the results over one of the above datasets.\n",
      "=== Calling Function ===\n",
      "Calling function: vector_tool_AURORA with args: {\"query\": \"results over CAMS analysis data\"}\n",
      "=== Function Output ===\n",
      "Aurora is competitive with CAMS on 95% of all targets, and matches or outperforms CAMS on 74% of all targets. At the three-day mark, Aurora is competitive with CAMS on all variables and matches or outperforms CAMS on 86% of all variables. However, Aurora is outperformed by CAMS on ozone in the very upper atmosphere and the twelve-hour prediction of all species in the lower part of the atmosphere. This is primarily because variables near the surface and in the lower part of the atmosphere are mainly affected by anthropogenic factors, which Aurora does not explicitly account for.\n",
      "=== LLM Response ===\n",
      "Aurora is competitive with CAMS on 95% of all targets and matches or outperforms CAMS on 74% of all targets. At the three-day mark, Aurora is competitive with CAMS on all variables and matches or outperforms CAMS on 86% of all variables. However, Aurora is outperformed by CAMS on ozone in the very upper atmosphere and the twelve-hour prediction of all species in the lower part of the atmosphere. This is primarily because variables near the surface and in the lower part of the atmosphere are mainly affected by anthropogenic factors, which Aurora does not explicitly account for.\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"Tell me the results over one of the above datasets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc4e983",
   "metadata": {},
   "source": [
    "## Lower-Level: Debuggability and Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55abad72-b189-471a-accc-1621fd19c804",
   "metadata": {
    "height": 115,
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    [vector_tool, summary_tool], \n",
    "    llm=llm, \n",
    "    verbose=True\n",
    ")\n",
    "agent = AgentRunner(agent_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18e911aa-4640-4f89-99c8-6cdf6aff07c6",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [],
   "source": [
    "task = agent.create_task(\n",
    "   \"What experimental results validate Aurora's performance in predicting air pollution?, \"\n",
    "    \"How does Aurora adapt to the non-stationary and scarce data from CAMS analysis?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5eaf0b88-e03a-4dd9-91f6-f6f0c8758e64",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What experimental results validate Aurora's performance in predicting air pollution?, How does Aurora adapt to the non-stationary and scarce data from CAMS analysis?\n",
      "=== Calling Function ===\n",
      "Calling function: vector_tool_AURORA with args: {\"query\": \"experimental results validate Aurora's performance in predicting air pollution\"}\n",
      "=== Function Output ===\n",
      "Experimental results validate Aurora's performance in predicting air pollution.\n",
      "=== Calling Function ===\n",
      "Calling function: vector_tool_AURORA with args: {\"query\": \"How does Aurora adapt to the non-stationary and scarce data from CAMS analysis?\"}\n",
      "=== Function Output ===\n",
      "Aurora adapts to the non-stationary and scarce data from CAMS analysis by fine-tuning on CAMS analysis data from Oct 2017 to May 2022 and testing on CAMS analysis data from May 2022 to Nov 2022. Additionally, to better learn the dynamics of the pollutants, Aurora also incorporates lower resolution and CAMS reanalysis data from Jan 2003 to Dec 2021 in the fine-tuning process. This approach helps Aurora implicitly learn to account for the effects of natural and anthropogenic factors despite the challenges posed by the non-stationary and scarce nature of the CAMS analysis data.\n"
     ]
    }
   ],
   "source": [
    "step_output = agent.run_step(task.task_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8e77fac-8734-4071-a672-b3a9f30e2bf1",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num completed for task 736f8b3d-47a3-4b93-a852-44ee4707a594: 1\n",
      "Experimental results validate Aurora's performance in predicting air pollution.\n"
     ]
    }
   ],
   "source": [
    "completed_steps = agent.get_completed_steps(task.task_id)\n",
    "print(f\"Num completed for task {task.task_id}: {len(completed_steps)}\")\n",
    "print(completed_steps[0].output.sources[0].raw_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db8de410-4b82-4daf-93da-28da57cbb0bb",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num upcoming steps for task 736f8b3d-47a3-4b93-a852-44ee4707a594: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskStep(task_id='736f8b3d-47a3-4b93-a852-44ee4707a594', step_id='05d173b1-b1be-4bcf-90ec-3ad5d4f4b4ff', input=None, step_state={}, next_steps={}, prev_steps={}, is_ready=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upcoming_steps = agent.get_upcoming_steps(task.task_id)\n",
    "print(f\"Num upcoming steps for task {task.task_id}: {len(upcoming_steps)}\")\n",
    "upcoming_steps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc352582-2c17-46ef-ba80-0f571e920c3c",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Explain the key tenets of foundation models mentioned in the introduction.\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_AURORA with args: {\"input\": \"key tenets of foundation models mentioned in the introduction\"}\n",
      "=== Function Output ===\n",
      "The key tenets of foundation models mentioned in the introduction include pretraining on diverse datasets to capture intricate patterns, fine-tuning for excelling at new tasks with limited data, operating at different resolutions, showcasing superior forecasting skills, leveraging scaling properties of AI for improved accuracy, resolution, and adaptability, serving as few-shot learners, providing accurate medium-range global weather forecasting, utilizing a 3D Perceiver encoder and Multi-scale 3D Swin Transformer U-Net backbone for simulating physics, incorporating positional, scale, level, and time encodings for essential information, normalizing data for consistency, handling air pollution variables effectively, utilizing various datasets for training and evaluation, fine-tuning on specific datasets with varying learning rates, evaluating performance through metrics like RMSE and ACC, and assessing forecast quality through power spectra analysis.\n"
     ]
    }
   ],
   "source": [
    "step_output = agent.run_step(\n",
    "    task.task_id, input=\"Explain the key tenets of foundation models mentioned in the introduction.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be80661f-81b1-45fc-b0ba-33a04dae849b",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LLM Response ===\n",
      "The key tenets of foundation models mentioned in the introduction include pretraining on diverse datasets, fine-tuning for new tasks with limited data, operating at different resolutions, showcasing superior forecasting skills, leveraging scaling properties of AI, serving as few-shot learners, providing accurate global weather forecasting, utilizing advanced encoders and backbones, incorporating essential encodings, normalizing data, handling air pollution variables effectively, utilizing various datasets, fine-tuning with varying learning rates, evaluating performance through metrics like RMSE and ACC, and assessing forecast quality through power spectra analysis.\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "step_output = agent.run_step(task.task_id)\n",
    "print(step_output.is_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4496328c-e6d5-4722-a8df-78a73a441b3c",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = agent.finalize_response(task.task_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "601d1bed-78b2-4512-87ac-aec5ce5d8494",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: The key tenets of foundation models mentioned in the introduction include pretraining on diverse datasets, fine-tuning for new tasks with limited data, operating at different resolutions, showcasing superior forecasting skills, leveraging scaling properties of AI, serving as few-shot learners, providing accurate global weather forecasting, utilizing advanced encoders and backbones, incorporating essential encodings, normalizing data, handling air pollution variables effectively, utilizing various datasets, fine-tuning with varying learning rates, evaluating performance through metrics like RMSE and ACC, and assessing forecast quality through power spectra analysis.\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d13d314",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
